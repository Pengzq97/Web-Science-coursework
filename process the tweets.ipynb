{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparation work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "before start \n",
    "pip install -U spacy \n",
    "pip install regex\n",
    "pip install nltk(if needed)\n",
    "pip install json\n",
    "pip install emoji\n",
    "pip install textblob\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import nltk\n",
    "import spacy\n",
    "import regex as re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('parser', <spacy.pipeline.pipes.DependencyParser at 0x1fd4c00d828>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md', disable=['ner'])\n",
    "nlp.remove_pipe('tagger')\n",
    "nlp.remove_pipe('parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrun these code if needed\\nnltk.download(\"corpus\")\\nnltk.download(\"stopwords\")\\nnltk.download(\\'punkt\\')\\nnltk.download(\\'wordnet\\')\\nnltk.download(\\'averaged_perceptron_tagger\\')\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "run these code if needed\n",
    "nltk.download(\"corpus\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process from json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and filter the data from jason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load json (scot) into a list\n",
    "raw_data_list = []\n",
    "with open('sample_data.json','r') as tweets:\n",
    "    line=tweets.readline()\n",
    "    for line in tweets:\n",
    "        if line != '\\n':\n",
    "            dic=json.loads(line)\n",
    "            raw_data_list.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of tweets get: 131849\n"
     ]
    }
   ],
   "source": [
    "print('the number of tweets get:',len(raw_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### clean scot topic data\n",
    "cleaned_data_list=[]\n",
    "for data in raw_data_list:\n",
    "    if 'text'in data.keys() and 'truncated' in data.keys():\n",
    "        if len(data['text'])!=139 and len(data['text'])!=140 and data['lang'] =='en' and len(data['text'])>60:\n",
    "            cleaned_data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the  number of qualified tweets: 29821\n"
     ]
    }
   ],
   "source": [
    "print('the  number of qualified tweets:',len(cleaned_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating the dataframe\n",
    "basicdata=[]\n",
    "for i in range(len(cleaned_data_list)):\n",
    "    basicdata.append([cleaned_data_list[i]['id'],cleaned_data_list[i]['created_at'],cleaned_data_list[i]['text'],len(cleaned_data_list[i]['text'])])\n",
    "df=pd.DataFrame(basicdata,columns=['id','time','text','length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### add hash tag list into the dataframe\n",
    "hashtag_list=[]\n",
    "for i in range(0,len(cleaned_data_list)):\n",
    "    hashtag_each_list=[]\n",
    "    if len(cleaned_data_list[i]['entities']['hashtags'])!=0:\n",
    "        for j in range(0,len(cleaned_data_list[i]['entities']['hashtags'])):\n",
    "            hashtag_each_list.append(cleaned_data_list[i]['entities']['hashtags'][j]['text'])\n",
    "    \n",
    "    if hashtag_each_list:\n",
    "        hashtag_list.append(hashtag_each_list)\n",
    "    else:\n",
    "        hashtag_list.append('')\n",
    "\n",
    "df['hash tags']=hashtag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncode for deleting df columns\\n\\ndf.drop(labels='hash1',axis=1,inplace=True)\\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "code for deleting df columns\n",
    "\n",
    "df.drop(labels='hash1',axis=1,inplace=True)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract emoji "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define a function to extract emojis (return a list)\n",
    "def extract_emojis(str):\n",
    "    emoji_list=[]\n",
    "    for c in str:\n",
    "        if c in emoji.UNICODE_EMOJI:\n",
    "            emoji_list.append(c)\n",
    "    return emoji_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract emoji from the text and load them into the data frame\n",
    "emoji_lists=[]\n",
    "for i in range(0,len(df)):\n",
    "    emoji_lists.append(extract_emojis(df.iloc[i].at['text']))\n",
    "df['emoji']=emoji_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>hash tags</th>\n",
       "      <th>emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1236305964870938624</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...</td>\n",
       "      <td>138</td>\n",
       "      <td>[Happy, TAEYEON, íƒœì—°, ì†Œë…€ì‹œëŒ€, GirlsGeneration, íƒœì—°...</td>\n",
       "      <td>[ğŸ€]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1236305965395234817</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...</td>\n",
       "      <td>138</td>\n",
       "      <td>[Happy, TAEYEON, íƒœì—°, ì†Œë…€ì‹œëŒ€, GirlsGeneration, íƒœì—°...</td>\n",
       "      <td>[ğŸ€]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1236305965546213376</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...</td>\n",
       "      <td>138</td>\n",
       "      <td>[Happy, TAEYEON, íƒœì—°, ì†Œë…€ì‹œëŒ€, GirlsGeneration, íƒœì—°...</td>\n",
       "      <td>[ğŸ€]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1236305965718417417</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @missradders: Someone needs to hold him to ...</td>\n",
       "      <td>74</td>\n",
       "      <td></td>\n",
       "      <td>[ğŸ‘—]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1236305966292926466</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @espn: MEAN MUG BRON ğŸ˜¤\\n\\nLeBron has been u...</td>\n",
       "      <td>111</td>\n",
       "      <td></td>\n",
       "      <td>[ğŸ˜¤]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29816</td>\n",
       "      <td>1236355889751343107</td>\n",
       "      <td>Sat Mar 07 18:19:49 +0000 2020</td>\n",
       "      <td>RT @SteveChopz: Found someone special in Idivi...</td>\n",
       "      <td>77</td>\n",
       "      <td></td>\n",
       "      <td>[ğŸ˜†]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29817</td>\n",
       "      <td>1236355889998651392</td>\n",
       "      <td>Sat Mar 07 18:19:49 +0000 2020</td>\n",
       "      <td>People will stay hating cause they see you doi...</td>\n",
       "      <td>126</td>\n",
       "      <td></td>\n",
       "      <td>[ğŸ˜Œ, ğŸ¤·, ğŸ», â™‚, ğŸ˜†]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29818</td>\n",
       "      <td>1236355893496893441</td>\n",
       "      <td>Sat Mar 07 18:19:50 +0000 2020</td>\n",
       "      <td>RT @TheDoors: Happy Birthday to legendary arti...</td>\n",
       "      <td>148</td>\n",
       "      <td>[ArthurLee, Love]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29819</td>\n",
       "      <td>1236355895103229953</td>\n",
       "      <td>Sat Mar 07 18:19:50 +0000 2020</td>\n",
       "      <td>RT @SportingKC: @Chiefs ğŸ‘Š Got another trophy f...</td>\n",
       "      <td>63</td>\n",
       "      <td></td>\n",
       "      <td>[ğŸ‘Š]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29820</td>\n",
       "      <td>1236355897238138881</td>\n",
       "      <td>Sat Mar 07 18:19:50 +0000 2020</td>\n",
       "      <td>RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...</td>\n",
       "      <td>138</td>\n",
       "      <td>[Happy, TAEYEON, íƒœì—°, ì†Œë…€ì‹œëŒ€, GirlsGeneration, íƒœì—°...</td>\n",
       "      <td>[ğŸ€]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29821 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                            time  \\\n",
       "0      1236305964870938624  Sat Mar 07 15:01:26 +0000 2020   \n",
       "1      1236305965395234817  Sat Mar 07 15:01:26 +0000 2020   \n",
       "2      1236305965546213376  Sat Mar 07 15:01:26 +0000 2020   \n",
       "3      1236305965718417417  Sat Mar 07 15:01:26 +0000 2020   \n",
       "4      1236305966292926466  Sat Mar 07 15:01:26 +0000 2020   \n",
       "...                    ...                             ...   \n",
       "29816  1236355889751343107  Sat Mar 07 18:19:49 +0000 2020   \n",
       "29817  1236355889998651392  Sat Mar 07 18:19:49 +0000 2020   \n",
       "29818  1236355893496893441  Sat Mar 07 18:19:50 +0000 2020   \n",
       "29819  1236355895103229953  Sat Mar 07 18:19:50 +0000 2020   \n",
       "29820  1236355897238138881  Sat Mar 07 18:19:50 +0000 2020   \n",
       "\n",
       "                                                    text  length  \\\n",
       "0      RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...     138   \n",
       "1      RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...     138   \n",
       "2      RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...     138   \n",
       "3      RT @missradders: Someone needs to hold him to ...      74   \n",
       "4      RT @espn: MEAN MUG BRON ğŸ˜¤\\n\\nLeBron has been u...     111   \n",
       "...                                                  ...     ...   \n",
       "29816  RT @SteveChopz: Found someone special in Idivi...      77   \n",
       "29817  People will stay hating cause they see you doi...     126   \n",
       "29818  RT @TheDoors: Happy Birthday to legendary arti...     148   \n",
       "29819  RT @SportingKC: @Chiefs ğŸ‘Š Got another trophy f...      63   \n",
       "29820  RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...     138   \n",
       "\n",
       "                                               hash tags            emoji  \n",
       "0      [Happy, TAEYEON, íƒœì—°, ì†Œë…€ì‹œëŒ€, GirlsGeneration, íƒœì—°...              [ğŸ€]  \n",
       "1      [Happy, TAEYEON, íƒœì—°, ì†Œë…€ì‹œëŒ€, GirlsGeneration, íƒœì—°...              [ğŸ€]  \n",
       "2      [Happy, TAEYEON, íƒœì—°, ì†Œë…€ì‹œëŒ€, GirlsGeneration, íƒœì—°...              [ğŸ€]  \n",
       "3                                                                     [ğŸ‘—]  \n",
       "4                                                                     [ğŸ˜¤]  \n",
       "...                                                  ...              ...  \n",
       "29816                                                                 [ğŸ˜†]  \n",
       "29817                                                     [ğŸ˜Œ, ğŸ¤·, ğŸ», â™‚, ğŸ˜†]  \n",
       "29818                                  [ArthurLee, Love]               []  \n",
       "29819                                                                 [ğŸ‘Š]  \n",
       "29820  [Happy, TAEYEON, íƒœì—°, ì†Œë…€ì‹œëŒ€, GirlsGeneration, íƒœì—°...              [ğŸ€]  \n",
       "\n",
       "[29821 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process the text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define the function of tokenize and normalize \n",
    "\n",
    "#@Tokenize\n",
    "def spacy_tokenize(string):\n",
    "    tokens = []\n",
    "    doc = nlp(string)\n",
    "    for token in doc:\n",
    "        tokens.append(token)\n",
    "    return tokens\n",
    "\n",
    "#@Normalize\n",
    "def normalize(tokens):\n",
    "    normalized_tokens = []\n",
    "    for token in tokens:\n",
    "        normalized = token.text.lower().strip()\n",
    "        if ((token.is_alpha or token.is_digit)):\n",
    "            normalized_tokens.append(normalized)\n",
    "    return normalized_tokens\n",
    "\n",
    "#@Tokenize and normalize\n",
    "def tokenize_normalize(string):\n",
    "    return normalize(spacy_tokenize(string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tokenization and normalize text\n",
    "text_list=df.iloc[:,2]\n",
    "normalized_textlist=[]\n",
    "for line in text_list:\n",
    "    normalized_textlist.append(tokenize_normalize(line))\n",
    "df['cleaned text']=normalized_textlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### normalize the hash tags\n",
    "tags_list=df.iloc[:,4]\n",
    "normalized_tags_list=[]\n",
    "for tags in tags_list:\n",
    "    normalized_tags=[]\n",
    "    for tag in tags:\n",
    "        normalized_tag=tokenize_normalize(tag)\n",
    "        if normalized_tag:\n",
    "            normalized_tags.append(normalized_tag[0])\n",
    "        else:\n",
    "            normalized_tags.append('')\n",
    "    normalized_tags_list.append(normalized_tags)\n",
    "df['hash tags']=normalized_tags_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lemmazatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define a function to get the TAG of each word in sentence\n",
    "wnl = WordNetLemmatizer()\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### processing and lemmatize the words in sentences \n",
    "lemmatized_list=[]\n",
    "for sentence in normalized_textlist:\n",
    "    tagged_sent = pos_tag(sentence)\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmas_sent = []\n",
    "    for tag in tagged_sent:\n",
    "        wordnet_pos = get_wordnet_pos(tag[1]) or wordnet.NOUN\n",
    "        lemmas_sent.append(wnl.lemmatize(tag[0], pos=wordnet_pos)) \n",
    "    lemmatized_list.append(lemmas_sent)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>hash tags</th>\n",
       "      <th>emoji</th>\n",
       "      <th>cleaned text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1236305964870938624</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...</td>\n",
       "      <td>138</td>\n",
       "      <td>[happy, taeyeon, íƒœì—°, ì†Œë…€ì‹œëŒ€, girlsgeneration, íƒœì—°...</td>\n",
       "      <td>[ğŸ€]</td>\n",
       "      <td>[rt, taeyeon, íƒœì—°, happy, photoshoot, behind, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1236305965395234817</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...</td>\n",
       "      <td>138</td>\n",
       "      <td>[happy, taeyeon, íƒœì—°, ì†Œë…€ì‹œëŒ€, girlsgeneration, íƒœì—°...</td>\n",
       "      <td>[ğŸ€]</td>\n",
       "      <td>[rt, taeyeon, íƒœì—°, happy, photoshoot, behind, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1236305965546213376</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...</td>\n",
       "      <td>138</td>\n",
       "      <td>[happy, taeyeon, íƒœì—°, ì†Œë…€ì‹œëŒ€, girlsgeneration, íƒœì—°...</td>\n",
       "      <td>[ğŸ€]</td>\n",
       "      <td>[rt, taeyeon, íƒœì—°, happy, photoshoot, behind, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1236305965718417417</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @missradders: Someone needs to hold him to ...</td>\n",
       "      <td>74</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ‘—]</td>\n",
       "      <td>[rt, someone, need, to, hold, him, to, this, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1236305966292926466</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @espn: MEAN MUG BRON ğŸ˜¤\\n\\nLeBron has been u...</td>\n",
       "      <td>111</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ˜¤]</td>\n",
       "      <td>[rt, mean, mug, bron, lebron, have, be, up, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29816</td>\n",
       "      <td>1236355889751343107</td>\n",
       "      <td>Sat Mar 07 18:19:49 +0000 2020</td>\n",
       "      <td>RT @SteveChopz: Found someone special in Idivi...</td>\n",
       "      <td>77</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ˜†]</td>\n",
       "      <td>[rt, find, someone, special, in, idivisible]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29817</td>\n",
       "      <td>1236355889998651392</td>\n",
       "      <td>Sat Mar 07 18:19:49 +0000 2020</td>\n",
       "      <td>People will stay hating cause they see you doi...</td>\n",
       "      <td>126</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ˜Œ, ğŸ¤·, ğŸ», â™‚, ğŸ˜†]</td>\n",
       "      <td>[people, will, stay, hat, cause, they, see, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29818</td>\n",
       "      <td>1236355893496893441</td>\n",
       "      <td>Sat Mar 07 18:19:50 +0000 2020</td>\n",
       "      <td>RT @TheDoors: Happy Birthday to legendary arti...</td>\n",
       "      <td>148</td>\n",
       "      <td>[arthurlee, love]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[rt, happy, birthday, to, legendary, artist, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29819</td>\n",
       "      <td>1236355895103229953</td>\n",
       "      <td>Sat Mar 07 18:19:50 +0000 2020</td>\n",
       "      <td>RT @SportingKC: @Chiefs ğŸ‘Š Got another trophy f...</td>\n",
       "      <td>63</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ‘Š]</td>\n",
       "      <td>[rt, get, another, trophy, for, kc, on, the, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29820</td>\n",
       "      <td>1236355897238138881</td>\n",
       "      <td>Sat Mar 07 18:19:50 +0000 2020</td>\n",
       "      <td>RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...</td>\n",
       "      <td>138</td>\n",
       "      <td>[happy, taeyeon, íƒœì—°, ì†Œë…€ì‹œëŒ€, girlsgeneration, íƒœì—°...</td>\n",
       "      <td>[ğŸ€]</td>\n",
       "      <td>[rt, taeyeon, íƒœì—°, happy, photoshoot, behind, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29821 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                            time  \\\n",
       "0      1236305964870938624  Sat Mar 07 15:01:26 +0000 2020   \n",
       "1      1236305965395234817  Sat Mar 07 15:01:26 +0000 2020   \n",
       "2      1236305965546213376  Sat Mar 07 15:01:26 +0000 2020   \n",
       "3      1236305965718417417  Sat Mar 07 15:01:26 +0000 2020   \n",
       "4      1236305966292926466  Sat Mar 07 15:01:26 +0000 2020   \n",
       "...                    ...                             ...   \n",
       "29816  1236355889751343107  Sat Mar 07 18:19:49 +0000 2020   \n",
       "29817  1236355889998651392  Sat Mar 07 18:19:49 +0000 2020   \n",
       "29818  1236355893496893441  Sat Mar 07 18:19:50 +0000 2020   \n",
       "29819  1236355895103229953  Sat Mar 07 18:19:50 +0000 2020   \n",
       "29820  1236355897238138881  Sat Mar 07 18:19:50 +0000 2020   \n",
       "\n",
       "                                                    text  length  \\\n",
       "0      RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...     138   \n",
       "1      RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...     138   \n",
       "2      RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...     138   \n",
       "3      RT @missradders: Someone needs to hold him to ...      74   \n",
       "4      RT @espn: MEAN MUG BRON ğŸ˜¤\\n\\nLeBron has been u...     111   \n",
       "...                                                  ...     ...   \n",
       "29816  RT @SteveChopz: Found someone special in Idivi...      77   \n",
       "29817  People will stay hating cause they see you doi...     126   \n",
       "29818  RT @TheDoors: Happy Birthday to legendary arti...     148   \n",
       "29819  RT @SportingKC: @Chiefs ğŸ‘Š Got another trophy f...      63   \n",
       "29820  RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...     138   \n",
       "\n",
       "                                               hash tags            emoji  \\\n",
       "0      [happy, taeyeon, íƒœì—°, ì†Œë…€ì‹œëŒ€, girlsgeneration, íƒœì—°...              [ğŸ€]   \n",
       "1      [happy, taeyeon, íƒœì—°, ì†Œë…€ì‹œëŒ€, girlsgeneration, íƒœì—°...              [ğŸ€]   \n",
       "2      [happy, taeyeon, íƒœì—°, ì†Œë…€ì‹œëŒ€, girlsgeneration, íƒœì—°...              [ğŸ€]   \n",
       "3                                                     []              [ğŸ‘—]   \n",
       "4                                                     []              [ğŸ˜¤]   \n",
       "...                                                  ...              ...   \n",
       "29816                                                 []              [ğŸ˜†]   \n",
       "29817                                                 []  [ğŸ˜Œ, ğŸ¤·, ğŸ», â™‚, ğŸ˜†]   \n",
       "29818                                  [arthurlee, love]               []   \n",
       "29819                                                 []              [ğŸ‘Š]   \n",
       "29820  [happy, taeyeon, íƒœì—°, ì†Œë…€ì‹œëŒ€, girlsgeneration, íƒœì—°...              [ğŸ€]   \n",
       "\n",
       "                                            cleaned text  \n",
       "0      [rt, taeyeon, íƒœì—°, happy, photoshoot, behind, t...  \n",
       "1      [rt, taeyeon, íƒœì—°, happy, photoshoot, behind, t...  \n",
       "2      [rt, taeyeon, íƒœì—°, happy, photoshoot, behind, t...  \n",
       "3      [rt, someone, need, to, hold, him, to, this, i...  \n",
       "4      [rt, mean, mug, bron, lebron, have, be, up, to...  \n",
       "...                                                  ...  \n",
       "29816       [rt, find, someone, special, in, idivisible]  \n",
       "29817  [people, will, stay, hat, cause, they, see, yo...  \n",
       "29818  [rt, happy, birthday, to, legendary, artist, a...  \n",
       "29819  [rt, get, another, trophy, for, kc, on, the, m...  \n",
       "29820  [rt, taeyeon, íƒœì—°, happy, photoshoot, behind, t...  \n",
       "\n",
       "[29821 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load cleaned text into dataframe and double check if it worked\n",
    "df['cleaned text']=lemmatized_list\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eliminate the duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating a fake list to put all tokens in \n",
    "processing_cleaned_list=[]\n",
    "for words in df.iloc[:,6]:\n",
    "    text=''\n",
    "    for word in words:\n",
    "        text=text+' '+word\n",
    "    processing_cleaned_list.append(text)\n",
    "df['processing index']=processing_cleaned_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate the dupilication by indentifying same fake string\n",
    "df.drop_duplicates(subset='processing index',keep='first',inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.drop(labels='processing index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>hash tags</th>\n",
       "      <th>emoji</th>\n",
       "      <th>cleaned text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1236305964870938624</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...</td>\n",
       "      <td>138</td>\n",
       "      <td>[happy, taeyeon, íƒœì—°, ì†Œë…€ì‹œëŒ€, girlsgeneration, íƒœì—°...</td>\n",
       "      <td>[ğŸ€]</td>\n",
       "      <td>[rt, taeyeon, íƒœì—°, happy, photoshoot, behind, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1236305965718417417</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @missradders: Someone needs to hold him to ...</td>\n",
       "      <td>74</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ‘—]</td>\n",
       "      <td>[rt, someone, need, to, hold, him, to, this, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1236305966292926466</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @espn: MEAN MUG BRON ğŸ˜¤\\n\\nLeBron has been u...</td>\n",
       "      <td>111</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ˜¤]</td>\n",
       "      <td>[rt, mean, mug, bron, lebron, have, be, up, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1236305966846500868</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @Sy_JOYstar: 180512  HQ\\nEvery day missing ...</td>\n",
       "      <td>111</td>\n",
       "      <td>[ì¡°ì´, joy, ë°•ìˆ˜ì˜, ë ˆë“œë²¨ë²³, redvelvet]</td>\n",
       "      <td>[ğŸ’š]</td>\n",
       "      <td>[rt, 180512, hq, every, day, miss, you, ì¡°ì´, jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1236305968138518530</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>@goonermarky1 Big ğŸ’š to you &amp;amp; the #Family ğŸ‘Š...</td>\n",
       "      <td>69</td>\n",
       "      <td>[family]</td>\n",
       "      <td>[ğŸ’š, ğŸ‘Š, ğŸ»]</td>\n",
       "      <td>[big, to, you, amp, the, family, have, a, grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10660</td>\n",
       "      <td>1236355863507603458</td>\n",
       "      <td>Sat Mar 07 18:19:42 +0000 2020</td>\n",
       "      <td>Follow me on Instagram @alijeet11 \\n|\\n|\\n|\\n|...</td>\n",
       "      <td>137</td>\n",
       "      <td>[poetry, love, poetrycommunity, writersofinsta...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[follow, me, on, instagram, poetry, love, poet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10661</td>\n",
       "      <td>1236355872160243712</td>\n",
       "      <td>Sat Mar 07 18:19:44 +0000 2020</td>\n",
       "      <td>It's the #sight of it that will stop your #kid...</td>\n",
       "      <td>119</td>\n",
       "      <td>[sight, kids]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[it, the, sight, of, it, that, will, stop, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10662</td>\n",
       "      <td>1236355873997344768</td>\n",
       "      <td>Sat Mar 07 18:19:45 +0000 2020</td>\n",
       "      <td>Inglewood Dad Caps â¤ï¸\\nNow Available https://t...</td>\n",
       "      <td>135</td>\n",
       "      <td>[inglewood, theforum, randysdonuts, souvenir, ...</td>\n",
       "      <td>[â¤]</td>\n",
       "      <td>[inglewood, dad, cap, now, available, inglewoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10663</td>\n",
       "      <td>1236355884638523393</td>\n",
       "      <td>Sat Mar 07 18:19:47 +0000 2020</td>\n",
       "      <td>Lol the comments.\\n\\nThought they had a diamon...</td>\n",
       "      <td>63</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ˜†]</td>\n",
       "      <td>[lol, the, comment, think, they, have, a, diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10664</td>\n",
       "      <td>1236355889998651392</td>\n",
       "      <td>Sat Mar 07 18:19:49 +0000 2020</td>\n",
       "      <td>People will stay hating cause they see you doi...</td>\n",
       "      <td>126</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ˜Œ, ğŸ¤·, ğŸ», â™‚, ğŸ˜†]</td>\n",
       "      <td>[people, will, stay, hat, cause, they, see, yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10665 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                            time  \\\n",
       "0      1236305964870938624  Sat Mar 07 15:01:26 +0000 2020   \n",
       "1      1236305965718417417  Sat Mar 07 15:01:26 +0000 2020   \n",
       "2      1236305966292926466  Sat Mar 07 15:01:26 +0000 2020   \n",
       "3      1236305966846500868  Sat Mar 07 15:01:26 +0000 2020   \n",
       "4      1236305968138518530  Sat Mar 07 15:01:26 +0000 2020   \n",
       "...                    ...                             ...   \n",
       "10660  1236355863507603458  Sat Mar 07 18:19:42 +0000 2020   \n",
       "10661  1236355872160243712  Sat Mar 07 18:19:44 +0000 2020   \n",
       "10662  1236355873997344768  Sat Mar 07 18:19:45 +0000 2020   \n",
       "10663  1236355884638523393  Sat Mar 07 18:19:47 +0000 2020   \n",
       "10664  1236355889998651392  Sat Mar 07 18:19:49 +0000 2020   \n",
       "\n",
       "                                                    text  length  \\\n",
       "0      RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...     138   \n",
       "1      RT @missradders: Someone needs to hold him to ...      74   \n",
       "2      RT @espn: MEAN MUG BRON ğŸ˜¤\\n\\nLeBron has been u...     111   \n",
       "3      RT @Sy_JOYstar: 180512  HQ\\nEvery day missing ...     111   \n",
       "4      @goonermarky1 Big ğŸ’š to you &amp; the #Family ğŸ‘Š...      69   \n",
       "...                                                  ...     ...   \n",
       "10660  Follow me on Instagram @alijeet11 \\n|\\n|\\n|\\n|...     137   \n",
       "10661  It's the #sight of it that will stop your #kid...     119   \n",
       "10662  Inglewood Dad Caps â¤ï¸\\nNow Available https://t...     135   \n",
       "10663  Lol the comments.\\n\\nThought they had a diamon...      63   \n",
       "10664  People will stay hating cause they see you doi...     126   \n",
       "\n",
       "                                               hash tags            emoji  \\\n",
       "0      [happy, taeyeon, íƒœì—°, ì†Œë…€ì‹œëŒ€, girlsgeneration, íƒœì—°...              [ğŸ€]   \n",
       "1                                                     []              [ğŸ‘—]   \n",
       "2                                                     []              [ğŸ˜¤]   \n",
       "3                        [ì¡°ì´, joy, ë°•ìˆ˜ì˜, ë ˆë“œë²¨ë²³, redvelvet]              [ğŸ’š]   \n",
       "4                                               [family]        [ğŸ’š, ğŸ‘Š, ğŸ»]   \n",
       "...                                                  ...              ...   \n",
       "10660  [poetry, love, poetrycommunity, writersofinsta...               []   \n",
       "10661                                      [sight, kids]               []   \n",
       "10662  [inglewood, theforum, randysdonuts, souvenir, ...              [â¤]   \n",
       "10663                                                 []              [ğŸ˜†]   \n",
       "10664                                                 []  [ğŸ˜Œ, ğŸ¤·, ğŸ», â™‚, ğŸ˜†]   \n",
       "\n",
       "                                            cleaned text  \n",
       "0      [rt, taeyeon, íƒœì—°, happy, photoshoot, behind, t...  \n",
       "1      [rt, someone, need, to, hold, him, to, this, i...  \n",
       "2      [rt, mean, mug, bron, lebron, have, be, up, to...  \n",
       "3      [rt, 180512, hq, every, day, miss, you, ì¡°ì´, jo...  \n",
       "4      [big, to, you, amp, the, family, have, a, grea...  \n",
       "...                                                  ...  \n",
       "10660  [follow, me, on, instagram, poetry, love, poet...  \n",
       "10661  [it, the, sight, of, it, that, will, stop, you...  \n",
       "10662  [inglewood, dad, cap, now, available, inglewoo...  \n",
       "10663  [lol, the, comment, think, they, have, a, diam...  \n",
       "10664  [people, will, stay, hat, cause, they, see, yo...  \n",
       "\n",
       "[10665 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check the data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correct spelling and drop off stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correted_textlist=[]\n",
    "#for line in normalized_textlist:\n",
    "    #ew_line=[]\n",
    "    #for word in line:\n",
    "        #blob=TextBlob(word)\n",
    "        #new_line.append(str(blob.correct()))\n",
    "    #correted_textlist.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['cleaned text']=correted_textlist\n",
    "#for words in textlist:\n",
    "    #if words in stopwords.words('english'):\n",
    "        #words.remove(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the class for hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_classes=[[\"happy\",\"glad\",\"love\",\"cheer\", \"enjoy\", \"joy\",\"happiness\",\"smile\"],\n",
    "         [\"comfort\",\"confident\",\"relax\",\"content\",\"satisfied\"],\n",
    "         [\"exciting\", \"excited\",'amazing'],\n",
    "         [\"sad\", \"tense\", \"frustration\",\"distressed\"],\n",
    "         [\"afraid\", \"alarm\", \"anxiety\", \"concerned\", \"disgust\",\"horrible\",\"panic\"],\n",
    "         [\"angry\", \"annoyed\", \"bear\",\"mood\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mark the hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_marks_hashtag=[[],[],[],[],[],[]]\n",
    "processing_list_hashtags=df.iloc[:,4]\n",
    "for tags in processing_list_hashtags:\n",
    "    for i in range(0,len(hashtag_classes)):\n",
    "        set_processing= set(tags)&set(hashtag_classes[i])\n",
    "        if set_processing:\n",
    "            class_marks_hashtag[i].append(len(set_processing))\n",
    "        else:\n",
    "            class_marks_hashtag[i].append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define emoji classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_classes=[[emoji.emojize(':laughing:',use_aliases=True),emoji.emojize(':smile:',use_aliases=True),emoji.emojize(':kissing_heart:',use_aliases=True),emoji.emojize(':heart:',use_aliases=True),emoji.emojize(':grin:',use_aliases=True)],\n",
    "               [emoji.emojize(':blush:',use_aliases=True),emoji.emojize(':relaxed:',use_aliases=True)],\n",
    "               [emoji.emojize(':exclamation:',use_aliases=True), emoji.emojize(':punch:',use_aliases=True),emoji.emojize(':heart_eyes:',use_aliases=True)],\n",
    "               [emoji.emojize(':cry:',use_aliases=True),emoji.emojize(':sob:',use_aliases=True),emoji.emojize(':broken_heart:',use_aliases=True)],\n",
    "               [emoji.emojize(':scream:',use_aliases=True), emoji.emojize(':fearful:',use_aliases=True), emoji.emojize(':worried:',use_aliases=True)],\n",
    "               [emoji.emojize(':rage:',use_aliases=True), emoji.emojize(':angry:',use_aliases=True), emoji.emojize(':triumph:',use_aliases=True),emoji.emojize(':imp:',use_aliases=True)]]                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ğŸ˜†', 'ğŸ˜„', 'ğŸ˜˜', 'â¤', 'ğŸ˜'],\n",
       " ['ğŸ˜Š', 'â˜º'],\n",
       " ['â—', 'ğŸ‘Š', 'ğŸ˜'],\n",
       " ['ğŸ˜¢', 'ğŸ˜­', 'ğŸ’”'],\n",
       " ['ğŸ˜±', 'ğŸ˜¨', 'ğŸ˜Ÿ'],\n",
       " ['ğŸ˜¡', 'ğŸ˜ ', 'ğŸ˜¤', 'ğŸ‘¿']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mark the emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_marks_emoji=[[],[],[],[],[],[]]\n",
    "processing_list_emoji=df.iloc[:,5]\n",
    "for tags in processing_list_emoji:\n",
    "    for i in range(0,len(emoji_classes)):\n",
    "        set_processing= set(tags)&set(emoji_classes[i])\n",
    "        if set_processing:\n",
    "            class_marks_emoji[i].append(0.5*len(set_processing))\n",
    "        else:\n",
    "            class_marks_emoji[i].append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load mark into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_marks=[[],[],[],[],[],[]]\n",
    "for i in range(0,len(class_marks)):\n",
    "    class_marks[i]=np.sum([class_marks_emoji[i],class_marks_hashtag[i]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>hash tags</th>\n",
       "      <th>emoji</th>\n",
       "      <th>cleaned text</th>\n",
       "      <th>happy</th>\n",
       "      <th>positive</th>\n",
       "      <th>excitement</th>\n",
       "      <th>surprise</th>\n",
       "      <th>fear</th>\n",
       "      <th>angry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1236305964870938624</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...</td>\n",
       "      <td>138</td>\n",
       "      <td>[happy, taeyeon, íƒœì—°, ì†Œë…€ì‹œëŒ€, girlsgeneration, íƒœì—°...</td>\n",
       "      <td>[ğŸ€]</td>\n",
       "      <td>[rt, taeyeon, íƒœì—°, happy, photoshoot, behind, t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1236305965718417417</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @missradders: Someone needs to hold him to ...</td>\n",
       "      <td>74</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ‘—]</td>\n",
       "      <td>[rt, someone, need, to, hold, him, to, this, i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1236305966292926466</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @espn: MEAN MUG BRON ğŸ˜¤\\n\\nLeBron has been u...</td>\n",
       "      <td>111</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ˜¤]</td>\n",
       "      <td>[rt, mean, mug, bron, lebron, have, be, up, to...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1236305966846500868</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @Sy_JOYstar: 180512  HQ\\nEvery day missing ...</td>\n",
       "      <td>111</td>\n",
       "      <td>[ì¡°ì´, joy, ë°•ìˆ˜ì˜, ë ˆë“œë²¨ë²³, redvelvet]</td>\n",
       "      <td>[ğŸ’š]</td>\n",
       "      <td>[rt, 180512, hq, every, day, miss, you, ì¡°ì´, jo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1236305968138518530</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>@goonermarky1 Big ğŸ’š to you &amp;amp; the #Family ğŸ‘Š...</td>\n",
       "      <td>69</td>\n",
       "      <td>[family]</td>\n",
       "      <td>[ğŸ’š, ğŸ‘Š, ğŸ»]</td>\n",
       "      <td>[big, to, you, amp, the, family, have, a, grea...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10660</td>\n",
       "      <td>1236355863507603458</td>\n",
       "      <td>Sat Mar 07 18:19:42 +0000 2020</td>\n",
       "      <td>Follow me on Instagram @alijeet11 \\n|\\n|\\n|\\n|...</td>\n",
       "      <td>137</td>\n",
       "      <td>[poetry, love, poetrycommunity, writersofinsta...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[follow, me, on, instagram, poetry, love, poet...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10661</td>\n",
       "      <td>1236355872160243712</td>\n",
       "      <td>Sat Mar 07 18:19:44 +0000 2020</td>\n",
       "      <td>It's the #sight of it that will stop your #kid...</td>\n",
       "      <td>119</td>\n",
       "      <td>[sight, kids]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[it, the, sight, of, it, that, will, stop, you...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10662</td>\n",
       "      <td>1236355873997344768</td>\n",
       "      <td>Sat Mar 07 18:19:45 +0000 2020</td>\n",
       "      <td>Inglewood Dad Caps â¤ï¸\\nNow Available https://t...</td>\n",
       "      <td>135</td>\n",
       "      <td>[inglewood, theforum, randysdonuts, souvenir, ...</td>\n",
       "      <td>[â¤]</td>\n",
       "      <td>[inglewood, dad, cap, now, available, inglewoo...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10663</td>\n",
       "      <td>1236355884638523393</td>\n",
       "      <td>Sat Mar 07 18:19:47 +0000 2020</td>\n",
       "      <td>Lol the comments.\\n\\nThought they had a diamon...</td>\n",
       "      <td>63</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ˜†]</td>\n",
       "      <td>[lol, the, comment, think, they, have, a, diam...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10664</td>\n",
       "      <td>1236355889998651392</td>\n",
       "      <td>Sat Mar 07 18:19:49 +0000 2020</td>\n",
       "      <td>People will stay hating cause they see you doi...</td>\n",
       "      <td>126</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ˜Œ, ğŸ¤·, ğŸ», â™‚, ğŸ˜†]</td>\n",
       "      <td>[people, will, stay, hat, cause, they, see, yo...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10665 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                            time  \\\n",
       "0      1236305964870938624  Sat Mar 07 15:01:26 +0000 2020   \n",
       "1      1236305965718417417  Sat Mar 07 15:01:26 +0000 2020   \n",
       "2      1236305966292926466  Sat Mar 07 15:01:26 +0000 2020   \n",
       "3      1236305966846500868  Sat Mar 07 15:01:26 +0000 2020   \n",
       "4      1236305968138518530  Sat Mar 07 15:01:26 +0000 2020   \n",
       "...                    ...                             ...   \n",
       "10660  1236355863507603458  Sat Mar 07 18:19:42 +0000 2020   \n",
       "10661  1236355872160243712  Sat Mar 07 18:19:44 +0000 2020   \n",
       "10662  1236355873997344768  Sat Mar 07 18:19:45 +0000 2020   \n",
       "10663  1236355884638523393  Sat Mar 07 18:19:47 +0000 2020   \n",
       "10664  1236355889998651392  Sat Mar 07 18:19:49 +0000 2020   \n",
       "\n",
       "                                                    text  length  \\\n",
       "0      RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...     138   \n",
       "1      RT @missradders: Someone needs to hold him to ...      74   \n",
       "2      RT @espn: MEAN MUG BRON ğŸ˜¤\\n\\nLeBron has been u...     111   \n",
       "3      RT @Sy_JOYstar: 180512  HQ\\nEvery day missing ...     111   \n",
       "4      @goonermarky1 Big ğŸ’š to you &amp; the #Family ğŸ‘Š...      69   \n",
       "...                                                  ...     ...   \n",
       "10660  Follow me on Instagram @alijeet11 \\n|\\n|\\n|\\n|...     137   \n",
       "10661  It's the #sight of it that will stop your #kid...     119   \n",
       "10662  Inglewood Dad Caps â¤ï¸\\nNow Available https://t...     135   \n",
       "10663  Lol the comments.\\n\\nThought they had a diamon...      63   \n",
       "10664  People will stay hating cause they see you doi...     126   \n",
       "\n",
       "                                               hash tags            emoji  \\\n",
       "0      [happy, taeyeon, íƒœì—°, ì†Œë…€ì‹œëŒ€, girlsgeneration, íƒœì—°...              [ğŸ€]   \n",
       "1                                                     []              [ğŸ‘—]   \n",
       "2                                                     []              [ğŸ˜¤]   \n",
       "3                        [ì¡°ì´, joy, ë°•ìˆ˜ì˜, ë ˆë“œë²¨ë²³, redvelvet]              [ğŸ’š]   \n",
       "4                                               [family]        [ğŸ’š, ğŸ‘Š, ğŸ»]   \n",
       "...                                                  ...              ...   \n",
       "10660  [poetry, love, poetrycommunity, writersofinsta...               []   \n",
       "10661                                      [sight, kids]               []   \n",
       "10662  [inglewood, theforum, randysdonuts, souvenir, ...              [â¤]   \n",
       "10663                                                 []              [ğŸ˜†]   \n",
       "10664                                                 []  [ğŸ˜Œ, ğŸ¤·, ğŸ», â™‚, ğŸ˜†]   \n",
       "\n",
       "                                            cleaned text  happy  positive  \\\n",
       "0      [rt, taeyeon, íƒœì—°, happy, photoshoot, behind, t...    1.0       0.0   \n",
       "1      [rt, someone, need, to, hold, him, to, this, i...    0.0       0.0   \n",
       "2      [rt, mean, mug, bron, lebron, have, be, up, to...    0.0       0.0   \n",
       "3      [rt, 180512, hq, every, day, miss, you, ì¡°ì´, jo...    1.0       0.0   \n",
       "4      [big, to, you, amp, the, family, have, a, grea...    0.0       0.0   \n",
       "...                                                  ...    ...       ...   \n",
       "10660  [follow, me, on, instagram, poetry, love, poet...    1.0       0.0   \n",
       "10661  [it, the, sight, of, it, that, will, stop, you...    0.0       0.0   \n",
       "10662  [inglewood, dad, cap, now, available, inglewoo...    1.5       0.0   \n",
       "10663  [lol, the, comment, think, they, have, a, diam...    0.5       0.0   \n",
       "10664  [people, will, stay, hat, cause, they, see, yo...    0.5       0.0   \n",
       "\n",
       "       excitement  surprise  fear  angry  \n",
       "0             0.0       0.0   0.0    0.0  \n",
       "1             0.0       0.0   0.0    0.0  \n",
       "2             0.0       0.0   0.0    0.5  \n",
       "3             0.0       0.0   0.0    0.0  \n",
       "4             0.5       0.0   0.0    0.0  \n",
       "...           ...       ...   ...    ...  \n",
       "10660         0.0       0.0   0.0    0.0  \n",
       "10661         0.0       0.0   0.0    0.0  \n",
       "10662         0.0       0.0   0.0    0.0  \n",
       "10663         0.0       0.0   0.0    0.0  \n",
       "10664         0.0       0.0   0.0    0.0  \n",
       "\n",
       "[10665 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['happy']=class_marks[0]\n",
    "df['positive']=class_marks[1]\n",
    "df['excitement']=class_marks[2]\n",
    "df['surprise']=class_marks[3]\n",
    "df['fear']=class_marks[4]\n",
    "df['angry']=class_marks[5]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find the max mark and label the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### loop the mark and find the best to label\n",
    "max_list=[]\n",
    "labels=[]\n",
    "for i in range(0,len(df)):\n",
    "    max=0\n",
    "    order=0\n",
    "    for j in range(0,len(class_marks)):\n",
    "        if class_marks[j][i]>max:\n",
    "            max=class_marks[j][i]\n",
    "            order=j\n",
    "    max_list.append(max)\n",
    "    if order==0:\n",
    "        labels.append('happy')\n",
    "    elif order==1:\n",
    "        labels.append('positive')\n",
    "    elif order==2:\n",
    "        labels.append('excitement')\n",
    "    elif order==3:\n",
    "        labels.append('surprise')\n",
    "    elif order==4:\n",
    "        labels.append('fear')\n",
    "    elif order==5:\n",
    "        labels.append('angry')\n",
    "        \n",
    "df['max_mark']=max_list\n",
    "df['label']=labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>hash tags</th>\n",
       "      <th>emoji</th>\n",
       "      <th>cleaned text</th>\n",
       "      <th>happy</th>\n",
       "      <th>positive</th>\n",
       "      <th>excitement</th>\n",
       "      <th>surprise</th>\n",
       "      <th>fear</th>\n",
       "      <th>angry</th>\n",
       "      <th>max_mark</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1236305964870938624</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...</td>\n",
       "      <td>138</td>\n",
       "      <td>[happy, taeyeon, íƒœì—°, ì†Œë…€ì‹œëŒ€, girlsgeneration, íƒœì—°...</td>\n",
       "      <td>[ğŸ€]</td>\n",
       "      <td>[rt, taeyeon, íƒœì—°, happy, photoshoot, behind, t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1236305965718417417</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @missradders: Someone needs to hold him to ...</td>\n",
       "      <td>74</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ‘—]</td>\n",
       "      <td>[rt, someone, need, to, hold, him, to, this, i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1236305966292926466</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @espn: MEAN MUG BRON ğŸ˜¤\\n\\nLeBron has been u...</td>\n",
       "      <td>111</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ˜¤]</td>\n",
       "      <td>[rt, mean, mug, bron, lebron, have, be, up, to...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1236305966846500868</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>RT @Sy_JOYstar: 180512  HQ\\nEvery day missing ...</td>\n",
       "      <td>111</td>\n",
       "      <td>[ì¡°ì´, joy, ë°•ìˆ˜ì˜, ë ˆë“œë²¨ë²³, redvelvet]</td>\n",
       "      <td>[ğŸ’š]</td>\n",
       "      <td>[rt, 180512, hq, every, day, miss, you, ì¡°ì´, jo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1236305968138518530</td>\n",
       "      <td>Sat Mar 07 15:01:26 +0000 2020</td>\n",
       "      <td>@goonermarky1 Big ğŸ’š to you &amp;amp; the #Family ğŸ‘Š...</td>\n",
       "      <td>69</td>\n",
       "      <td>[family]</td>\n",
       "      <td>[ğŸ’š, ğŸ‘Š, ğŸ»]</td>\n",
       "      <td>[big, to, you, amp, the, family, have, a, grea...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>excitement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10660</td>\n",
       "      <td>1236355863507603458</td>\n",
       "      <td>Sat Mar 07 18:19:42 +0000 2020</td>\n",
       "      <td>Follow me on Instagram @alijeet11 \\n|\\n|\\n|\\n|...</td>\n",
       "      <td>137</td>\n",
       "      <td>[poetry, love, poetrycommunity, writersofinsta...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[follow, me, on, instagram, poetry, love, poet...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10661</td>\n",
       "      <td>1236355872160243712</td>\n",
       "      <td>Sat Mar 07 18:19:44 +0000 2020</td>\n",
       "      <td>It's the #sight of it that will stop your #kid...</td>\n",
       "      <td>119</td>\n",
       "      <td>[sight, kids]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[it, the, sight, of, it, that, will, stop, you...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10662</td>\n",
       "      <td>1236355873997344768</td>\n",
       "      <td>Sat Mar 07 18:19:45 +0000 2020</td>\n",
       "      <td>Inglewood Dad Caps â¤ï¸\\nNow Available https://t...</td>\n",
       "      <td>135</td>\n",
       "      <td>[inglewood, theforum, randysdonuts, souvenir, ...</td>\n",
       "      <td>[â¤]</td>\n",
       "      <td>[inglewood, dad, cap, now, available, inglewoo...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10663</td>\n",
       "      <td>1236355884638523393</td>\n",
       "      <td>Sat Mar 07 18:19:47 +0000 2020</td>\n",
       "      <td>Lol the comments.\\n\\nThought they had a diamon...</td>\n",
       "      <td>63</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ˜†]</td>\n",
       "      <td>[lol, the, comment, think, they, have, a, diam...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10664</td>\n",
       "      <td>1236355889998651392</td>\n",
       "      <td>Sat Mar 07 18:19:49 +0000 2020</td>\n",
       "      <td>People will stay hating cause they see you doi...</td>\n",
       "      <td>126</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ğŸ˜Œ, ğŸ¤·, ğŸ», â™‚, ğŸ˜†]</td>\n",
       "      <td>[people, will, stay, hat, cause, they, see, yo...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10665 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                            time  \\\n",
       "0      1236305964870938624  Sat Mar 07 15:01:26 +0000 2020   \n",
       "1      1236305965718417417  Sat Mar 07 15:01:26 +0000 2020   \n",
       "2      1236305966292926466  Sat Mar 07 15:01:26 +0000 2020   \n",
       "3      1236305966846500868  Sat Mar 07 15:01:26 +0000 2020   \n",
       "4      1236305968138518530  Sat Mar 07 15:01:26 +0000 2020   \n",
       "...                    ...                             ...   \n",
       "10660  1236355863507603458  Sat Mar 07 18:19:42 +0000 2020   \n",
       "10661  1236355872160243712  Sat Mar 07 18:19:44 +0000 2020   \n",
       "10662  1236355873997344768  Sat Mar 07 18:19:45 +0000 2020   \n",
       "10663  1236355884638523393  Sat Mar 07 18:19:47 +0000 2020   \n",
       "10664  1236355889998651392  Sat Mar 07 18:19:49 +0000 2020   \n",
       "\n",
       "                                                    text  length  \\\n",
       "0      RT @GirlsGeneration: TAEYEON íƒœì—° '#Happy' Photo...     138   \n",
       "1      RT @missradders: Someone needs to hold him to ...      74   \n",
       "2      RT @espn: MEAN MUG BRON ğŸ˜¤\\n\\nLeBron has been u...     111   \n",
       "3      RT @Sy_JOYstar: 180512  HQ\\nEvery day missing ...     111   \n",
       "4      @goonermarky1 Big ğŸ’š to you &amp; the #Family ğŸ‘Š...      69   \n",
       "...                                                  ...     ...   \n",
       "10660  Follow me on Instagram @alijeet11 \\n|\\n|\\n|\\n|...     137   \n",
       "10661  It's the #sight of it that will stop your #kid...     119   \n",
       "10662  Inglewood Dad Caps â¤ï¸\\nNow Available https://t...     135   \n",
       "10663  Lol the comments.\\n\\nThought they had a diamon...      63   \n",
       "10664  People will stay hating cause they see you doi...     126   \n",
       "\n",
       "                                               hash tags            emoji  \\\n",
       "0      [happy, taeyeon, íƒœì—°, ì†Œë…€ì‹œëŒ€, girlsgeneration, íƒœì—°...              [ğŸ€]   \n",
       "1                                                     []              [ğŸ‘—]   \n",
       "2                                                     []              [ğŸ˜¤]   \n",
       "3                        [ì¡°ì´, joy, ë°•ìˆ˜ì˜, ë ˆë“œë²¨ë²³, redvelvet]              [ğŸ’š]   \n",
       "4                                               [family]        [ğŸ’š, ğŸ‘Š, ğŸ»]   \n",
       "...                                                  ...              ...   \n",
       "10660  [poetry, love, poetrycommunity, writersofinsta...               []   \n",
       "10661                                      [sight, kids]               []   \n",
       "10662  [inglewood, theforum, randysdonuts, souvenir, ...              [â¤]   \n",
       "10663                                                 []              [ğŸ˜†]   \n",
       "10664                                                 []  [ğŸ˜Œ, ğŸ¤·, ğŸ», â™‚, ğŸ˜†]   \n",
       "\n",
       "                                            cleaned text  happy  positive  \\\n",
       "0      [rt, taeyeon, íƒœì—°, happy, photoshoot, behind, t...    1.0       0.0   \n",
       "1      [rt, someone, need, to, hold, him, to, this, i...    0.0       0.0   \n",
       "2      [rt, mean, mug, bron, lebron, have, be, up, to...    0.0       0.0   \n",
       "3      [rt, 180512, hq, every, day, miss, you, ì¡°ì´, jo...    1.0       0.0   \n",
       "4      [big, to, you, amp, the, family, have, a, grea...    0.0       0.0   \n",
       "...                                                  ...    ...       ...   \n",
       "10660  [follow, me, on, instagram, poetry, love, poet...    1.0       0.0   \n",
       "10661  [it, the, sight, of, it, that, will, stop, you...    0.0       0.0   \n",
       "10662  [inglewood, dad, cap, now, available, inglewoo...    1.5       0.0   \n",
       "10663  [lol, the, comment, think, they, have, a, diam...    0.5       0.0   \n",
       "10664  [people, will, stay, hat, cause, they, see, yo...    0.5       0.0   \n",
       "\n",
       "       excitement  surprise  fear  angry  max_mark       label  \n",
       "0             0.0       0.0   0.0    0.0       1.0       happy  \n",
       "1             0.0       0.0   0.0    0.0       0.0       happy  \n",
       "2             0.0       0.0   0.0    0.5       0.5       angry  \n",
       "3             0.0       0.0   0.0    0.0       1.0       happy  \n",
       "4             0.5       0.0   0.0    0.0       0.5  excitement  \n",
       "...           ...       ...   ...    ...       ...         ...  \n",
       "10660         0.0       0.0   0.0    0.0       1.0       happy  \n",
       "10661         0.0       0.0   0.0    0.0       0.0       happy  \n",
       "10662         0.0       0.0   0.0    0.0       1.5       happy  \n",
       "10663         0.0       0.0   0.0    0.0       0.5       happy  \n",
       "10664         0.0       0.0   0.0    0.0       0.5       happy  \n",
       "\n",
       "[10665 rows x 15 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete the potential ambiguous text and the text without right hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=df\n",
    "final_df=final_df[final_df.max_mark!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2226"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df[final_df.max_mark==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(labels='max mark',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  output csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze the number of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total numbers:  8880\n",
      "happy:  3837\n",
      "angry:  1790\n",
      "positive:  476\n",
      "excitement:  788\n",
      "surprise:  1788\n",
      "fear:  201\n"
     ]
    }
   ],
   "source": [
    "print('total numbers: ',len(final_df))\n",
    "print('happy: ',len(final_df[final_df.label=='happy']))\n",
    "print('angry: ',len(final_df[final_df.label=='angry']))\n",
    "print('positive: ',len(final_df[final_df.label=='positive']))\n",
    "print('excitement: ',len(final_df[final_df.label=='excitement']))\n",
    "print('surprise: ',len(final_df[final_df.label=='surprise']))\n",
    "print('fear: ',len(final_df[final_df.label=='fear']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data into 6 different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_happy=final_df[final_df.label=='happy']\n",
    "csv_angry=final_df[final_df.label=='angry']\n",
    "csv_positive=final_df[final_df.label=='positive']\n",
    "csv_excitement=final_df[final_df.label=='excitement']\n",
    "csv_surprise=final_df[final_df.label=='surprise']\n",
    "csv_fear=final_df[final_df.label=='fear']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output the data into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_happy.to_csv(\"csv_happy.csv\",encoding='utf-8',index=False)\n",
    "csv_angry.to_csv(\"csv_angry.csv\",encoding='utf-8',index=False)\n",
    "csv_positive.to_csv(\"csv_positive.csv\",encoding='utf-8',index=False)\n",
    "csv_excitement.to_csv(\"csv_excitement.csv\",encoding='utf-8',index=False)\n",
    "csv_surprise.to_csv(\"csv_surprise.csv\",encoding='utf-8',index=False)\n",
    "csv_fear.to_csv(\"csv_fear.csv\",encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.to_csv(\"fourth_csv.csv\",encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csv processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"all.csv\",encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
